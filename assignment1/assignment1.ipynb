{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog \n",
    "from numpy.linalg import solve\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and parsing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "url = \"http://www.nordpoolspot.com/globalassets/marketdata-excel-files/consumption-prognosis_2019_hourly.xls\" \n",
    "urllib.request.urlretrieve(url, 'data/consumption.xls');\n",
    "\n",
    "url2 = \"http://www.nordpoolspot.com/globalassets/marketdata-excel-files/wind-power-dk-prognosis_2019_hourly.xls\" \n",
    "urllib.request.urlretrieve(url2, 'data/wind-prognosis.xls');\n",
    "\n",
    "consumptionProg_raw_data = pd.read_html('data/consumption.xls')[0].values\n",
    "consumptionProg_df = pd.DataFrame(consumptionProg_raw_data)\n",
    "consumptionProg_df.columns = ['Dates', 'Hours', 'NO', 'SE', 'FI', 'DK1', 'DK2', 'EE', 'LV', 'LT']\n",
    "consumptionProg_df = consumptionProg_df[['Dates', 'Hours', 'DK1', 'DK2']]\n",
    "consumptionProg_df['Hours'] = consumptionProg_df['Hours'].str.slice(stop=2)\n",
    "consumptionProg_df['ts'] = pd.to_datetime(consumptionProg_df['Dates'] + consumptionProg_df['Hours'] + ':00', format='%d-%m-%Y%H:%M')\n",
    "consumptionProg_df = consumptionProg_df[consumptionProg_df['ts'] < pd.to_datetime('2019-02-01')]\n",
    "\n",
    "## Including Import of DK1 -> Norway 200MW\n",
    "consumptionProg_df['DK1'] = consumptionProg_df['DK1'] + 200\n",
    "\n",
    "## Including Export of DK1 -> Germany 100MW\n",
    "for i in consumptionProg_df.index:\n",
    "    if (consumptionProg_df['ts'][i].time() >= pd.to_datetime('07:00:00').time()) & (windProg_df['ts'][i].time() < pd.to_datetime('14:00:00').time()):\n",
    "        consumptionProg_df['DK1'][i] = consumptionProg_df['DK1'][i] - 100\n",
    "        \n",
    "## Including Import of DK2 -> Sweden 150MW\n",
    "for i in consumptionProg_df.index:\n",
    "    if (consumptionProg_df['ts'][i].time() >= pd.to_datetime('07:00:00').time()) & (windProg_df['ts'][i].time() < pd.to_datetime('14:00:00').time()):\n",
    "        consumptionProg_df['DK2'][i] = consumptionProg_df['DK2'][i] + 150\n",
    "\n",
    "windProg_raw_data = pd.read_html('data/wind-prognosis.xls')[0].values\n",
    "windProg_df = pd.DataFrame(windProg_raw_data)\n",
    "windProg_df.columns = ['Dates', 'Hours', 'DK1', 'DK2']\n",
    "windProg_df['Hours'] = windProg_df['Hours'].str.slice(stop=2)\n",
    "windProg_df['ts'] = pd.to_datetime(windProg_df['Dates'] + windProg_df['Hours'] + ':00', format='%d-%m-%Y%H:%M')\n",
    "windProg_df = windProg_df[windProg_df['ts'] < pd.to_datetime('2019-02-01')]\n",
    "\n",
    "windProg_df['WW1'] = windProg_df['DK1']*(1/4)\n",
    "windProg_df['WW2'] = windProg_df['DK1']*(3/4)\n",
    "windProg_df['EW1'] = windProg_df['DK2']*(1/3)\n",
    "windProg_df['EW2'] = windProg_df['DK2']*(2/3)\n",
    "\n",
    "supply_all = np.array([[400, 330, 345, 390, 510, 1000, 900, 1200, 320, 360, 400, 350, 730, 630, 800],\n",
    "                       [70, 64, 153, 82, 89, 25, 250, 19, 43, 39, 36, 31, 5, 10, 250]])\n",
    "\n",
    "supply_all_df = pd.DataFrame(supply_all.T).rename(columns={0:'ID', 1:'Supply', 2:'Cost'})\n",
    "\n",
    "supply_restricted= np.array([[400, 330, 345, 390, 510, 900, 320, 360, 400, 350, 730, 630, 800],\n",
    "                             [70, 64, 153, 82, 89, 250, 43, 39, 36, 31, 5, 10, 250]])\n",
    "\n",
    "supply_restricted_df = pd.DataFrame(supply_restricted.T).rename(columns={0:'ID', 1:'Supply', 2:'Cost'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in windProg_df.index:\n",
    "    \n",
    "    power_d = consumptionProg_df.values[i,2:4]\n",
    "\n",
    "    if (windProg_df['ts'][i].time() >= pd.to_datetime('05:00:00').time()) & (windProg_df['ts'][i].time() < pd.to_datetime('22:00:00').time()):\n",
    "        power_g = np.concatenate((supply_restricted[0], windProg_df.values[i,5:]))\n",
    "        cost_g = np.concatenate((supply_restricted[1], [0 , 0, 0, 0]))\n",
    "    else:\n",
    "        power_g = np.concatenate((supply_all[0], windProg_df.values[i,5:]))\n",
    "        cost_g = np.concatenate((supply_restricted[1], [0 , 0, 0, 0]))\n",
    "\n",
    "    print(windProg_df['ts'][i], '- Units: ', power_g.shape[0])\n",
    "    print('Pg: ', power_g)\n",
    "    print('Cg: ', cost_g)\n",
    "    print('Pd: ', power_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_eq = np.array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 1.,  1., \n",
    "                  -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.]])\n",
    "b_eq = 0\n",
    "\n",
    "A = np.identity(A_eq.size)\n",
    "\n",
    "power_g = np.array([120, 50, 200, 400, 60, 50, 60, 100, 70, 50, 70, 45, 50, 60, 50]) \n",
    "power_d = np.array([250, 300, 120, 80, 40, 70, 60, 45, 30, 35, 25, 10]) \n",
    "b = np.array([np.concatenate((power_g, power_d))]).T\n",
    "\n",
    "cost_g = np.array([0, 0, 15, 30, 32.5, 34, 36, 37.5, 39, 40, 60, 70, 100, 150, 200])\n",
    "cost_d = -np.array([200, 110, 100, 90, 85, 75, 65, 40, 38, 31, 24, 16])\n",
    "c = np.concatenate((cost_g, cost_d))\n",
    "\n",
    "res_std = linprog(c, A_eq=A_eq, b_eq = b_eq, A_ub=A, b_ub=b, bounds=(0, None))\n",
    "print('Generation schedules:', res_std.x[:15])\n",
    "print('Demand schedules:', res_std.x[15:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.ones(15)\n",
    "a2 = -np.ones(12)\n",
    "a3 = np.array([np.hstack((a1,a2))]).T\n",
    "a4 = -np.identity(27)\n",
    "\n",
    "A_tilde = np.concatenate((a4,a3),axis=1)\n",
    "\n",
    "b_tilde = np.concatenate((cost_g, cost_d))\n",
    "\n",
    "c_tilde = np.append(-b, np.array([0]))\n",
    "\n",
    "res_dual = linprog(-c_tilde, A_ub=A_tilde, b_ub=b_tilde)\n",
    "print('Cost:', res_dual.x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppliers Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppliers_dict = {'G1' : 'FlexiGas',\n",
    "                 'G2' : 'FlexiGas',\n",
    "                 'G3' : 'FlexiGas',\n",
    "                 'G4' : 'Peako',\n",
    "                 'G5' : 'Peako',\n",
    "                 'G6' : 'Nuke22',\n",
    "                 'G7' : 'CoalAtLast',\n",
    "                 'G8' : 'Nuke22',\n",
    "                 'G9' : 'RoskildeCHP',\n",
    "                 'G10' : 'RoskildeCHP',\n",
    "                 'G11' : 'Avedovre',\n",
    "                 'G12' : 'Avedovre',\n",
    "                 'G13' : 'BlueWater',\n",
    "                 'G14' : 'BlueWater',\n",
    "                 'G15' : 'CoalAtLast'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1",
   "language": "python",
   "name": "assignment1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
